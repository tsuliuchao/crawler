# 抓取

## 操作方式
__抓取__: cd news/ && python3 main.py

## 抓取源头url
* [八卦绯闻-搜狐娱乐-滚动新闻](http://yule.sohu.com/roll/)
* [网易娱乐滚动](http://ent.163.com/latest/)
* [网易娱乐-wap首页](https://3g.163.com/touch/ent/#adaptation=pc&refer=http%3A%2F%2Fent.163.com%2Fspecial%2Fstar_news%2F)

# 相关文档
- [scrapy 官方手册](http://scrapy-chs.readthedocs.io/zh_CN/0.24/index.html)
- [scrapy 个人手册](https://github.com/yidao620c/core-scrapy)
- [pycharm下打开、执行并调试scrapy爬虫程序](https://blog.csdn.net/u012052268/article/details/72063917)
- [Scrapy定向爬虫教程(三)——爬取多个页面](https://blog.csdn.net/qq_30242609/article/details/52811018?locationNum=1&fps=1)
- [scrapy相关问题](docs/scrapyQuestion.md)

# 初始化环境
`
pip3.6 install sqlalchemy
pip install pymysql
`
